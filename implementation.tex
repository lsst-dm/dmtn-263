\section{Implementation}

There are two parts to this implementation:

\begin{enumerate}
\item The Postgres database and populating it.
\item Serving that up via TAP.
\end{enumerate}


No 2. here is well understood  - we have TAP services so we put one in front of the \DB

There are some choices to be made concerning No. 1.

Frossie provided the simple diagram \figref{fig:obsloctap} which captures the ideas.


\begin{figure}
\begin{centering}
\includegraphics[width=0.8\textwidth]{obsloctap}
	\caption{ Choices on how to populate the Postgres database for ObsLocTap.
\label{fig:obsloctap}}
\end{centering}
\end{figure}


\subsection{Create the table}
The yaml was added to {\code sdm\_schema} so Felis may be used to create the schema.

I did not find Felis on pips so I grabbed \url{git@github.com:lsst/felis.git} and installed it with {\tt pip install .}.

I also cloned \url{git@github.com:lsst/sdm_schemas.git}.

This allowed the Felis execution, database login and table creation:\footnote{ivoa. was removed  from th DDL} \\
\begin{code}
Felis create-all --engine-url="\$engine\_url" --dry-run  sdm\_schemas/yml/obsloctap.yaml > obsloctap.sql

psql -h usdf-butler-session.slac.stanford.edu -U rubin lsstdb1

lsstdb1=> create schema obsloctap;
lsstdb1=> create schema obsloctap\_dev;

SET SEARCH\_PATH = obsloctap\_dev;
\\i obsplan.sql
SET SEARCH\_PATH = obsloctap;
\\i obsplan.sql

\end{code}

Can check the default schema an if  it exists with:
\begin{code}
show SEARCH\_PATH ;
\\dt
\end{code}


\subsection{Populating the \DB}

Initially at least we should try plan A and do all of this at the USDF.
The EFD messages are replicated there so we can pick up the scheduler messages and process them via a stream processor in Kafka (within Sasquatch).
\subsubsection{24 hour schedule}
The 24 hour schedule may be access at USDF by a call to an API in rubin-sim 2.2.3+ \\
{\texttt sim\_archive.fetch\_obsloctap\_visits(nights=2)}.
This result can be processed and entries with priority 2 put in the obsplan table.
It should be robust against a second call so should always try to update or delete overlapping times.

\subsubsection{4 hour schedule}
Then we will process {\texttt lsst.sal.Scheduler.logevent\_predictedSchedule }\footnote{see \url{https://usdf-rsp.slac.stanford.edu/kafdrop/topic/lsst.sal.MTHeaderService.logevent_largeFileObjectAvailable}} to update/create schedule entries.

\subsubsection{Observation made}
Finally we will look at {\texttt lsst.sal.MTHeaderService.logevent\_largeFileObjectAvailable} which will give us a pointer to the header ({\texttt url} field) and using {\texttt astro\_metadata\_translator}  we can get r obsid, exposure\_id, filter and update the \DB appropriately.

\subsection{TAP service}

There is already a ticket \jira{DM-39729} for the creation of the Felis schema.
Another is needed to expose this via tap.

Along the lines of separation of security concerns this would be deployed on the Cloud (US DAC) not in USDF.

Currently the endpoint /schedule will return the last 1K lines from the Obsplan table as a json file.
This is deployed only on usdfdev as of Dec 2023.
\url{https://usdf-rsp-dev.slac.stanford.edu/obsloctap/schedule}
It only contains test rows.


\subsection{Phalanx}
Deployment is with Phalanx  see \url{https://phalanx.lsst.io/index.html}.
Specifically \url{https://phalanx.lsst.io/applications/obsloctap/index.html}.


