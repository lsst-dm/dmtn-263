\section{Implementation}

There are two parts to this implementation:

\begin{enumerate}
\item The Postgres database and populating it.
\item Serving that up via TAP.
\end{enumerate}


No 2. here is well understood  - we have TAP services so we put one in front of the \DB

There are some choices to be made concerning No. 1.

Frossie provided the simple diagram \figref{fig:obsloctap} which captures the ideas.


\begin{figure}
\begin{centering}
\includegraphics[width=0.8\textwidth]{obsloctap}
	\caption{ Choices on how to populate the Postgres database for ObsLocTap.
\label{fig:obsloctap}}
\end{centering}
\end{figure}


\subsection{Create the table}
The yaml was added to {\code sdm\_schema} so Felis may be used to create the schema.

I did not find Felis on pips so I grabbed \url{git@github.com:lsst/felis.git} and installed it with {\tt pip install .}.

I also cloned \url{git@github.com:lsst/sdm_schemas.git}.

This allowed the Felis execution, database login and table creation:\footnote{ivoa. was removed  from th DDL} \\
\begin{code}
Felis create-all --engine-url="\$engine\_url" --dry-run  sdm\_schemas/yml/obsloctap.yaml > obsloctap.sql

psql -h usdf-butler-session.slac.stanford.edu -U rubin lsstdb1

lsstdb1=> create schema obsloctap;
lsstdb1=> create schema obsloctap\_dev;

SET SEARCH\_PATH = obsloctap\_dev;
\textbackslash{}\textbackslash{}i obsplan.sql

\textbackslash{}\textbackslash{}SET SEARCH\_PATH = obsloctap;
\textbackslash{}\textbackslash{}i obsplan.sql

\end{code}

Can check the default schema an if  it exists with:
\begin{code}
show SEARCH\_PATH ;
\\dt
\end{code}


\subsection{Populating the \DB}

Initially at least we should try plan A and do all of this at the USDF.
The EFD messages are replicated there so we can pick up the scheduler messages and process them via a stream processor in Kafka (within Sasquatch).
\subsubsection{24 hour schedule}
The 24 hour schedule may be access at USDF by a call to an API in rubin-sim 2.2.3+ \\
{\texttt sim\_archive.fetch\_obsloctap\_visits(nights=2)}.
This result can be processed and entries with priority 2 put in the obsplan table.
It should be robust against a second call so should always try to update or delete overlapping times.

In theory {\texttt target\_id} should be in this data i and propagates through the observing chain
but it is not yet provided .

The code for this is in schedule24.py.

\subsubsection{4 hour schedule}
Then we will process {\texttt lsst.sal.Scheduler.logevent\_predictedSchedule }\footnote{see \url{https://usdf-rsp.slac.stanford.edu/kafdrop/topic/lsst.sal.Scheduler.logevent_predictedSchedule/allmessages}} to update/create schedule entries.

The contents of this message are not as rich as the 24 hour schedule - but the code created Obsplan objects from them and attempts to do an update in the same manner as the 24 hour schedule.

The code for this is in consumekafka.py

\subsubsection{Observation made}
Finally we intended to  look at {\texttt lsst.sal.MTHeaderService.logevent\_largeFileObjectAvailable} which will give us a pointer to the header ({\texttt url} field) and using {\texttt astro\_metadata\_translator}  we can get r obsid, exposure\_id, filter and update the \DB appropriately.
However all of this is already in {\texttt ConsDB} so we though a query there would be more appropriate.

ConsDB schema is in {\texttt sql\_schemas}\footnote{\url{https://sdm-schemas.lsst.io/cdb_lsstcam.html}}.
Though there is a ConsDB\_query client in rubin\_nights - the current code accesses directly using the credentials passed to the container.  The query to get the observation data looks like this:

\begin{code}
SELECT exposure\_id,obs\_start\_mjd,obs\_end\_mjd,band,physical\_filter,s\_ra,s\_dec,target\_name,science\_program,scheduler\_note from cdb\_lsstcam.exposure where obs\_start\_mjd between 60858.98263978243 and 60859.98263978243 and can\_see\_sky = True order by obs\_start\_mjd
\end{code}

The numbers and the MJD stamps between which to search.

The code for this is in consdbhelp.py.

\subsubsection{Schedule loop}

Each of the 3 DB updates run at different cadences.
All are called from ScheduleLoop.py - which runs each in its own thread using asyncio runner.



\subsection{TAP service}

There is already a ticket \jira{DM-39729} for the creation of the Felis schema.
Another is needed to expose this via tap.

Along the lines of separation of security concerns this would be deployed on the Cloud (US DAC) not in USDF.

Currently the endpoint /schedule will return the next 24 hours from the Obsplan table as a json file.
This is deployed only on usdfdev as of Dec 2023
\url{https://usdf-rsp-dev.slac.stanford.edu/obsloctap/schedule?time=12}

and on production since July 2025
\url{https://usdf-rsp-dev.slac.stanford.edu/obsloctap/schedule?time=24}

The time parameter is the number of hours look ahead required,  a start time may also be provided  allowing one to look at historical entries.

As of July 2025 this is connected to the scheduler and provides the next 2 days schedule, it is update 12 hours.

Though not very efficient a simple rendering to HTML is provided at :
\url{https://usdf-rsp.slac.stanford.edu/obsloctap/static/viewer.html}

\subsection{Phalanx}
Deployment is with Phalanx  see \url{https://phalanx.lsst.io/index.html}.
Specifically \url{https://phalanx.lsst.io/applications/obsloctap/index.html}.


